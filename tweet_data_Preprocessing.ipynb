{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwe_x4eVjclW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import warnings\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing tweet data from drive"
      ],
      "metadata": {
        "id": "B8tRJr8ZVe0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Tweet.csv')\n",
        "company=pd.read_csv('/content/drive/MyDrive/Company.csv')\n",
        "com_tweet=pd.read_csv('/content/drive/MyDrive/Company_Tweet.csv')"
      ],
      "metadata": {
        "id": "1zqE981gk0vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a score column by adding number of comments, number of retweeets, number of likes"
      ],
      "metadata": {
        "id": "vJshSTmZVoc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data['score']=data['comment_num']+data['retweet_num']+data['like_num']\n",
        "data['post_date'] = pd.to_datetime(data['post_date'], unit='s')\n"
      ],
      "metadata": {
        "id": "AQSSUceMljBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_n=pd.merge(data,com_tweet,on='tweet_id',how='right')\n",
        "data_n['post_date']=pd.to_datetime(data_n['post_date'])\n",
        "data_n['post_date']=data_n['post_date'].dt.date\n"
      ],
      "metadata": {
        "id": "jo_LzZ_Arlc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unneccessary columns"
      ],
      "metadata": {
        "id": "XfwHvRyZV3Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_n=data_n.drop(['tweet_id','writer'],axis=1)\n"
      ],
      "metadata": {
        "id": "s38usPCU7X36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove data with score less than 10\n",
        "data_n=data_n[data_n['score']>=10]\n",
        "data_n"
      ],
      "metadata": {
        "id": "9KDVFWeNEo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_n=data_n.rename(columns={'post_date':'Date','ticker_symbol':'Ticker'})\n",
        "data_n"
      ],
      "metadata": {
        "id": "vDg8-902_hYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df = data_n.groupby(['Date', 'Ticker']).agg({\n",
        "    'body': lambda x: ' '.join(x),  # Concatenate the text from the 'body' column\n",
        "}).reset_index()\n",
        "data_n=grouped_df.set_index(['Date','Ticker'])\n"
      ],
      "metadata": {
        "id": "u4o66gky7AFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text cleaning and preprocessing"
      ],
      "metadata": {
        "id": "Jnm9kOOghrfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'https?://\\S+'\n",
        "data_n['body'] = data_n['body'].str.replace(pattern, ' ')\n",
        "pd.options.display.max_colwidth = 1000"
      ],
      "metadata": {
        "id": "-K8HnWu3vLb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter('ignore')\n",
        "data_n['body']=data_n['body'].str.replace('(\\@\\w+.*?)',\"\")\n",
        "data_n['body']=data_n['body'].str.replace('(\\#w+.*?)',\"\")"
      ],
      "metadata": {
        "id": "bUqeJ4T8ztVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_n.head()"
      ],
      "metadata": {
        "id": "dJU6rQ8Ty9mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading historical stock prices with yfinance\n",
        "# Configuring tickers and period\n",
        "ticker_symbols = [\"AAPL\", \"GOOG\", \"GOOGL\", \"AMZN\", \"TSLA\", \"MSFT\"]\n",
        "start_date = \"2015-01-01\"\n",
        "end_date = \"2019-12-31\"\n",
        "interval = \"1d\"\n",
        "\n",
        "# Adjusting all prices to stock splits and dividend payments\n",
        "auto_adjust = True\n",
        "\n",
        "# Using yfinance package to get data from Yahoo Finance for each ticker\n",
        "tickers = yf.Tickers(ticker_symbols)\n",
        "tickers_df = tickers.history(start=start_date, end=end_date, interval=interval, auto_adjust=auto_adjust)\n",
        "\n",
        "# Investigating data\n",
        "print(tickers_df.shape)\n",
        "tickers_df.head(20)"
      ],
      "metadata": {
        "id": "I6Rz4Bq01NaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df = tickers_df.stack(level=1).rename_axis(['Date', 'Ticker'])\n",
        "transformed_df.head(10)"
      ],
      "metadata": {
        "id": "jJJApEVBOw-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import Level\n",
        "# Choosing columns to keep\n",
        "cols = ['Close', 'Open', 'Volume']\n",
        "\n",
        "# Creating a new dataFrame with selected columns\n",
        "stock_df = transformed_df[cols].copy()\n",
        "\n",
        "\n",
        "def calculate_growth(x):\n",
        "    result = (x-x.shift(1))/x\n",
        "    return result\n",
        "def normalized_growth(x):\n",
        "    scaler=MinMaxScaler()\n",
        "    growth_series=x.dropna()\n",
        "    growth_df=growth_series.to_frame()\n",
        "    result= scaler.fit_transform(growth_df)\n",
        "    return result\n",
        "\n",
        "\n",
        "# Creating function for defining the Up (2), Stable (1), and Down (0) classes\n",
        "def create_multiclass(x):\n",
        "    result = 2 if x >= 0.50 else (0 if x <= 0.40 else 1)\n",
        "    return result\n",
        "\n",
        "stock_df['growth'] = stock_df.groupby(level='Ticker')['Close'].apply(calculate_growth)\n",
        "no_growth_rows = stock_df[stock_df['growth'].isna()]\n",
        "if len(no_growth_rows) > 0:\n",
        "    stock_df = stock_df.drop(no_growth_rows.index)\n",
        "stock_df['normalized_growth'] = normalized_growth(stock_df['growth'])\n",
        "# stock_df['Normalized_growth']=normalized_growth(stock_df['growth'])\n",
        "# Creating the multiclass target variable\n",
        "# Creating function for defining the Up (2), Stable (1), and Down (0) classes\n",
        "stock_df['target'] = stock_df['normalized_growth'].apply(create_multiclass)\n",
        "\n",
        "stock_df.head(20)"
      ],
      "metadata": {
        "id": "jVaZjbOWPsOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "E3fKrnQySzGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing columns to keep\n",
        "cols = ['Close', 'Open', 'Volume']\n",
        "\n",
        "# Creating a new dataFrame with selected columns\n",
        "stock_df = transformed_df[cols].copy()\n",
        "\n",
        "\n",
        "def calculate_log_change(x):\n",
        "    result = np.log(x) - np.log(x.shift(1))\n",
        "    return result\n",
        "\n",
        "def create_binary_variable(x):\n",
        "    result = np.where(x >= 0, 1, 0)\n",
        "    return result\n",
        "\n",
        "# Creating function for defining the Up (2), Stable (1), and Down (0) classes\n",
        "def create_multiclass(x):\n",
        "    result = 2 if x >= 0.005 else (0 if x <= -0.005 else 1)\n",
        "    return result\n",
        "\n",
        "# Creating columns for log returns and log volume change and ensuring that its calculated on individual ticker level\n",
        "stock_df['log_ret'] = stock_df.groupby(level='Ticker')['Close'].apply(calculate_log_change)\n",
        "stock_df['log_volume_change'] = stock_df.groupby(level='Ticker')['Volume'].apply(calculate_log_change)\n",
        "\n",
        "# Creating columns for binary variables\n",
        "# Value of 1 if equal or above 0, 0 if below\n",
        "stock_df['log_ret_binary'] = stock_df['log_ret'].apply(create_binary_variable)\n",
        "stock_df['log_volume_change_binary'] = stock_df['log_volume_change'].apply(create_binary_variable)\n",
        "\n",
        "# Creating the multiclass target variable\n",
        "# Creating function for defining the Up (2), Stable (1), and Down (0) classes\n",
        "stock_df['target'] = stock_df['log_ret'].apply(create_multiclass)\n",
        "\n",
        "stock_df.head(20)"
      ],
      "metadata": {
        "id": "mysFHMiEjQPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "YYTbloVoTCjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subset_values = price_data.iloc[1:-1, 1:].values.ravel()\n",
        "# sns.displot(subset_values, kind='kde')\n",
        "# plt.xlabel('Scaled Growth')\n",
        "# plt.ylabel('PDF')\n",
        "# plt.title('Distribution of Scaled Growth')\n",
        "# lower_bound = 0.40\n",
        "# upper_bound = 0.50\n",
        "# # Plot vertical lines to indicate the classification boundaries\n",
        "# plt.axvline(x=lower_bound, color='r', linestyle='--', label='Lower Bound')\n",
        "# plt.axvline(x=upper_bound, color='g', linestyle='--', label='Upper Bound')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "Jm1LqNkLqBn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.reset_index(inplace=True)\n",
        "stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
        "stock_df.set_index(['Date', 'Ticker'], inplace=True)\n",
        "stock_df"
      ],
      "metadata": {
        "id": "5F5kzyqOWsRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_2018 = pd.to_datetime(\"2018-12-31\")\n",
        "date_2019 = pd.to_datetime(\"2019-06-30\")\n",
        "\n",
        "train = data_n.loc[:date_2018]\n",
        "val = data_n.loc[date_2018:date_2019]\n",
        "test = data_n.loc[date_2019:]\n",
        "train_data = stock_df.loc[:date_2018]\n",
        "val_data = stock_df.loc[date_2018:date_2019]\n",
        "test_data = stock_df.loc[date_2019:]"
      ],
      "metadata": {
        "id": "VAaPpoXMbWpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train.join(train_data,how='inner')\n",
        "val_data=val.join(val_data,how='inner')\n",
        "test_data=test.join(test_data,how='inner')"
      ],
      "metadata": {
        "id": "UgUhnQL1Twv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data['target'].value_counts())\n",
        "print(val_data['target'].value_counts())\n",
        "print(test_data['target'].value_counts())"
      ],
      "metadata": {
        "id": "eQkqpb-LeTYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.drop(['Close','Open','Volume','log_volume_change','log_ret_binary','log_volume_change_binary','log_ret'],axis=1)\n",
        "val_data=val_data.drop(['Close','Open','Volume','log_volume_change','log_ret_binary','log_volume_change_binary','log_ret'],axis=1)\n",
        "test_data=test_data.drop(['Close','Open','Volume','log_volume_change','log_ret_binary','log_volume_change_binary','log_ret'],axis=1)\n",
        "y_test=test_data['target']"
      ],
      "metadata": {
        "id": "m3-bqdA7UIXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "xGyKJLdCJ4VM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}